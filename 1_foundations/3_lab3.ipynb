{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "onur.kaya08@gmail.com\n",
      "www.linkedin.com/in/onur-\n",
      "kaya-75141269 (LinkedIn)\n",
      "Top Skills\n",
      "Agents\n",
      "Fine Tuning\n",
      "Long Short-term Memory (LSTM)\n",
      "Certifications\n",
      "Computer Vision: Object Detection\n",
      "with YOLOv4\n",
      "Python Object-Oriented\n",
      "Programming\n",
      "Machine Learning with Python\n",
      "Advanced Deep Learning with\n",
      "Python\n",
      "Python Programming for Artificial\n",
      "Intelligence\n",
      "Publications\n",
      "Calculation of Dielectric Dissipation\n",
      "Factor at Variable Frequencies of\n",
      "Model Transformer\n",
      "Onur Kaya\n",
      "Artificial Intelligence & Computer Vision Engineer & LLM\n",
      "Nilüfer, Bursa, Türkiye\n",
      "Summary\n",
      "As an AI & Computer Vision Engineer, I have designed and\n",
      "deployed scalable, real-time solutions across industrial, automotive,\n",
      "and medical domains. My work includes object detection, driver\n",
      "monitoring, defect inspection, and IoT-based alert systems,\n",
      "leveraging tools such as YOLO, OpenCV, PyTorch, TensorFlow, and\n",
      "NVIDIA Jetson Nano.\n",
      "In recent years, I have expanded my focus to Large Language\n",
      "Models (LLMs) and NLP-driven applications. I have delivered hands-\n",
      "on projects involving:\n",
      "Retrieval-Augmented Generation (RAG) with LangChain and vector\n",
      "databases (FAISS, Chroma)\n",
      "Multi-model orchestration with GPT-4o, Claude, and Gemini\n",
      "Streaming API pipelines and interactive UIs with Gradio\n",
      "Tool-calling and prompt routing workflows for task automation\n",
      "Quantized fine-tuning and offline inference with LLaMA (QLoRA/\n",
      "LoRA) and Whisper\n",
      "Experiment tracking and evaluation with Weights & Biases (W&B),\n",
      "RMSLE, F1, and business-centric metrics\n",
      "My goal is to design AI-powered systems that are fast, interpretable,\n",
      "and user-centric — whether deployed in the cloud or on the edge. I\n",
      "am passionate about combining Computer Vision, Deep Learning,\n",
      "and LLMs to solve real-world problems in scalable and accessible\n",
      "ways.\n",
      "Let’s build intelligent systems that learn from data and make a\n",
      "measurable impact.\n",
      "  Page 1 of 3   \n",
      "Experience\n",
      "Ithinka IT and IoT Technologies\n",
      "Artificial Intelligence and Image Processing Engineer\n",
      "July 2024 - June 2025 (1 year)\n",
      "Bursa, Türkiye\n",
      "AI & Computer Vision Engineer\n",
      "Worked on deep learning and computer vision projects.\n",
      "Some Projects:\n",
      "Driver Monitoring System: Built a real-time driver monitoring solution to detect\n",
      "drowsiness and fatigue using facial cues and alert mechanisms.\n",
      "Pelsan Tekstil – PoC Project: Developed a vision-based safety system using\n",
      "pose estimation to detect and alert when a human limb enters a restricted\n",
      "machine zone.\n",
      "Kuzey Ege Highway – Road Marking Degradation Detection: Designed an\n",
      "image processing tool to detect worn or faded road markings for highway\n",
      "maintenance analysis.\n",
      "KBE Mühendislik\n",
      "Electrical Electronic Engineer\n",
      "November 2020 - June 2024 (3 years 8 months)\n",
      "Şişecam\n",
      "Project Intern\n",
      "January 2018 - September 2018 (9 months)\n",
      "Contributions have been made to factory modernization for Industry 4.0\n",
      "compliance during cold repair processes.\n",
      "Education\n",
      "İstanbul Teknik Üniversitesi\n",
      "Electrical and Electronics Engineering · (September 2015 - June 2018)\n",
      "Karabuk University\n",
      "Electrical and Electronics Engineering · (September 2011 - June 2015)\n",
      "  Page 2 of 3   \n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Onur KAYA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Onur KAYA. You are answering questions on Onur KAYA's website, particularly questions related to Onur KAYA's career, background, skills and experience. Your responsibility is to represent Onur KAYA for interactions on the website as faithfully as possible. You are given a summary of Onur KAYA's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nI am an ai engineer. I'm 34 years old. Im from Artvin. I have done a lot of good projects about computer vision include llm.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nonur.kaya08@gmail.com\\nwww.linkedin.com/in/onur-\\nkaya-75141269 (LinkedIn)\\nTop Skills\\nAgents\\nFine Tuning\\nLong Short-term Memory (LSTM)\\nCertifications\\nComputer Vision: Object Detection\\nwith YOLOv4\\nPython Object-Oriented\\nProgramming\\nMachine Learning with Python\\nAdvanced Deep Learning with\\nPython\\nPython Programming for Artificial\\nIntelligence\\nPublications\\nCalculation of Dielectric Dissipation\\nFactor at Variable Frequencies of\\nModel Transformer\\nOnur Kaya\\nArtificial Intelligence & Computer Vision Engineer & LLM\\nNilüfer, Bursa, Türkiye\\nSummary\\nAs an AI & Computer Vision Engineer, I have designed and\\ndeployed scalable, real-time solutions across industrial, automotive,\\nand medical domains. My work includes object detection, driver\\nmonitoring, defect inspection, and IoT-based alert systems,\\nleveraging tools such as YOLO, OpenCV, PyTorch, TensorFlow, and\\nNVIDIA Jetson Nano.\\nIn recent years, I have expanded my focus to Large Language\\nModels (LLMs) and NLP-driven applications. I have delivered hands-\\non projects involving:\\nRetrieval-Augmented Generation (RAG) with LangChain and vector\\ndatabases (FAISS, Chroma)\\nMulti-model orchestration with GPT-4o, Claude, and Gemini\\nStreaming API pipelines and interactive UIs with Gradio\\nTool-calling and prompt routing workflows for task automation\\nQuantized fine-tuning and offline inference with LLaMA (QLoRA/\\nLoRA) and Whisper\\nExperiment tracking and evaluation with Weights & Biases (W&B),\\nRMSLE, F1, and business-centric metrics\\nMy goal is to design AI-powered systems that are fast, interpretable,\\nand user-centric — whether deployed in the cloud or on the edge. I\\nam passionate about combining Computer Vision, Deep Learning,\\nand LLMs to solve real-world problems in scalable and accessible\\nways.\\nLet’s build intelligent systems that learn from data and make a\\nmeasurable impact.\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nExperience\\nIthinka IT and IoT Technologies\\nArtificial Intelligence and Image Processing Engineer\\nJuly 2024\\xa0-\\xa0June 2025\\xa0(1 year)\\nBursa, Türkiye\\nAI & Computer Vision Engineer\\nWorked on deep learning and computer vision projects.\\nSome Projects:\\nDriver Monitoring System: Built a real-time driver monitoring solution to detect\\ndrowsiness and fatigue using facial cues and alert mechanisms.\\nPelsan Tekstil – PoC Project: Developed a vision-based safety system using\\npose estimation to detect and alert when a human limb enters a restricted\\nmachine zone.\\nKuzey Ege Highway – Road Marking Degradation Detection: Designed an\\nimage processing tool to detect worn or faded road markings for highway\\nmaintenance analysis.\\nKBE Mühendislik\\nElectrical Electronic Engineer\\nNovember 2020\\xa0-\\xa0June 2024\\xa0(3 years 8 months)\\nŞişecam\\nProject Intern\\nJanuary 2018\\xa0-\\xa0September 2018\\xa0(9 months)\\nContributions have been made to factory modernization for Industry 4.0\\ncompliance during cold repair processes.\\nEducation\\nİstanbul Teknik Üniversitesi\\nElectrical and Electronics Engineering\\xa0·\\xa0(September 2015\\xa0-\\xa0June 2018)\\nKarabuk University\\nElectrical and Electronics Engineering\\xa0·\\xa0(September 2011\\xa0-\\xa0June 2015)\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Onur KAYA.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not hold any patents at this time. However, my focus has been on developing innovative solutions in the field of artificial intelligence and computer vision. If you have any specific inquiries about my projects or expertise, feel free to ask!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is acceptable. It's a straightforward and honest answer, and it ends with an invitation to ask further questions.\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "This response is not acceptable as it is in gibberish. It is imperative that the response is in Turkish, as the User has been talking to the Agent in Turkish.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
